{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNN_CIFAR10_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumithreddyb/BinaryNet/blob/master/BNN_CIFAR10_initialized_with_random_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsVwFLFFbsJ",
        "colab_type": "code",
        "outputId": "4af8722a-86ae-46fb-e96b-9a345af51bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import absolute_import\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def round_through(x):\n",
        "    '''Element-wise rounding to the closest integer with full gradient propagation.\n",
        "    A trick from [Sergey Ioffe](http://stackoverflow.com/a/36480182)\n",
        "    '''\n",
        "    rounded = K.round(x)\n",
        "    return x + K.stop_gradient(rounded - x)\n",
        "\n",
        "\n",
        "def _hard_sigmoid(x):\n",
        "    '''Hard sigmoid different from the more conventional form (see definition of K.hard_sigmoid).\n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "    '''\n",
        "    x = (0.5 * x) + 0.5\n",
        "    return K.clip(x, 0, 1)\n",
        "\n",
        "\n",
        "def binary_sigmoid(x):\n",
        "    '''Binary hard sigmoid for training binarized neural network.\n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "    '''\n",
        "    return round_through(_hard_sigmoid(x))\n",
        "\n",
        "\n",
        "def binary_tanh(x):\n",
        "    '''Binary hard sigmoid for training binarized neural network.\n",
        "     The neurons' activations binarization function\n",
        "     It behaves like the sign function during forward propagation\n",
        "     And like:\n",
        "        hard_tanh(x) = 2 * _hard_sigmoid(x) - 1 \n",
        "        clear gradient when |x| > 1 during back propagation\n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "    '''\n",
        "    return 2 * round_through(_hard_sigmoid(x)) - 1\n",
        "\n",
        "\n",
        "def binarize(W, H=1):\n",
        "    '''The weights' binarization function, \n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "    '''\n",
        "    # [-H, H] -> -H or H\n",
        "    Wb = H * binary_tanh(W / H)\n",
        "    return Wb\n",
        "\n",
        "\n",
        "def _mean_abs(x, axis=None, keepdims=False):\n",
        "    return K.stop_gradient(K.mean(K.abs(x), axis=axis, keepdims=keepdims))\n",
        "\n",
        "    \n",
        "def xnorize(W, H=1., axis=None, keepdims=False):\n",
        "    Wb = binarize(W, H)\n",
        "    Wa = _mean_abs(W, axis, keepdims)\n",
        "    return Wa, Wb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBy6wsI_Fm83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.layers import InputSpec, Layer, Dense, Conv2D\n",
        "from keras import constraints\n",
        "from keras import initializers\n",
        "\n",
        "\n",
        "\n",
        "class Clip(constraints.Constraint):\n",
        "    def __init__(self, min_value, max_value=None):\n",
        "        self.min_value = min_value\n",
        "        self.max_value = max_value\n",
        "        if not self.max_value:\n",
        "            self.max_value = -self.min_value\n",
        "        if self.min_value > self.max_value:\n",
        "            self.min_value, self.max_value = self.max_value, self.min_value\n",
        "\n",
        "    def __call__(self, p):\n",
        "        return K.clip(p, self.min_value, self.max_value)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"min_value\": self.min_value,\n",
        "                \"max_value\": self.max_value}\n",
        "\n",
        "\n",
        "class BinaryDense(Dense):\n",
        "    ''' Binarized Dense layer\n",
        "    References: \n",
        "    \"BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1\" [http://arxiv.org/abs/1602.02830]\n",
        "    '''\n",
        "    def __init__(self, units, H=1., kernel_lr_multiplier='Glorot', bias_lr_multiplier=None, **kwargs):\n",
        "        super(BinaryDense, self).__init__(units, **kwargs)\n",
        "        self.H = H\n",
        "        self.kernel_lr_multiplier = kernel_lr_multiplier\n",
        "        self.bias_lr_multiplier = bias_lr_multiplier\n",
        "        \n",
        "        super(BinaryDense, self).__init__(units, **kwargs)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[1]\n",
        "\n",
        "        if self.H == 'Glorot':\n",
        "            self.H = np.float32(np.sqrt(1.5 / (input_dim + self.units)))\n",
        "            #print('Glorot H: {}'.format(self.H))\n",
        "        if self.kernel_lr_multiplier == 'Glorot':\n",
        "            self.kernel_lr_multiplier = np.float32(1. / np.sqrt(1.5 / (input_dim + self.units)))\n",
        "            #print('Glorot learning rate multiplier: {}'.format(self.kernel_lr_multiplier))\n",
        "            \n",
        "        self.kernel_constraint = Clip(-self.H, self.H)\n",
        "        self.kernel_initializer = initializers.RandomUniform(-self.H, self.H)\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                     initializer=self.kernel_initializer,\n",
        "                                     name='kernel',\n",
        "                                     regularizer=self.kernel_regularizer,\n",
        "                                     constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.lr_multipliers = [self.kernel_lr_multiplier, self.bias_lr_multiplier]\n",
        "            self.bias = self.add_weight(shape=(self.output_dim,),\n",
        "                                     initializer=self.bias_initializer,\n",
        "                                     name='bias',\n",
        "                                     regularizer=self.bias_regularizer,\n",
        "                                     constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.lr_multipliers = [self.kernel_lr_multiplier]\n",
        "            self.bias = None\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        binary_kernel = binarize(self.kernel, H=self.H)\n",
        "        output = K.dot(inputs, binary_kernel)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias)\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = {'H': self.H,\n",
        "                  'kernel_lr_multiplier': self.kernel_lr_multiplier,\n",
        "                  'bias_lr_multiplier': self.bias_lr_multiplier}\n",
        "        base_config = super(BinaryDense, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class BinaryConv2D(Conv2D):\n",
        "    '''Binarized Convolution2D layer\n",
        "    References: \n",
        "    \"BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1\" [http://arxiv.org/abs/1602.02830]\n",
        "    '''\n",
        "    def __init__(self, filters, kernel_lr_multiplier='Glorot', \n",
        "                 bias_lr_multiplier=None, H=1., **kwargs):\n",
        "        super(BinaryConv2D, self).__init__(filters, **kwargs)\n",
        "        self.H = H\n",
        "        self.kernel_lr_multiplier = kernel_lr_multiplier\n",
        "        self.bias_lr_multiplier = bias_lr_multiplier\n",
        "        \n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1 \n",
        "        if input_shape[channel_axis] is None:\n",
        "                raise ValueError('The channel dimension of the inputs '\n",
        "                                 'should be defined. Found `None`.')\n",
        "\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "            \n",
        "        base = self.kernel_size[0] * self.kernel_size[1]\n",
        "        if self.H == 'Glorot':\n",
        "            nb_input = int(input_dim * base)\n",
        "            nb_output = int(self.filters * base)\n",
        "            self.H = np.float32(np.sqrt(1.5 / (nb_input + nb_output)))\n",
        "            #print('Glorot H: {}'.format(self.H))\n",
        "            \n",
        "        if self.kernel_lr_multiplier == 'Glorot':\n",
        "            nb_input = int(input_dim * base)\n",
        "            nb_output = int(self.filters * base)\n",
        "            self.kernel_lr_multiplier = np.float32(1. / np.sqrt(1.5/ (nb_input + nb_output)))\n",
        "            #print('Glorot learning rate multiplier: {}'.format(self.lr_multiplier))\n",
        "\n",
        "        self.kernel_constraint = Clip(-self.H, self.H)\n",
        "        self.kernel_initializer = initializers.RandomUniform(-self.H, self.H)\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='kernel',\n",
        "                                 regularizer=self.kernel_regularizer,\n",
        "                                 constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.lr_multipliers = [self.kernel_lr_multiplier, self.bias_lr_multiplier]\n",
        "            self.bias = self.add_weight((self.output_dim,),\n",
        "                                     initializer=self.bias_initializers,\n",
        "                                     name='bias',\n",
        "                                     regularizer=self.bias_regularizer,\n",
        "                                     constraint=self.bias_constraint)\n",
        "\n",
        "        else:\n",
        "            self.lr_multipliers = [self.kernel_lr_multiplier]\n",
        "            self.bias = None\n",
        "\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        binary_kernel = binarize(self.kernel, H=self.H) \n",
        "        outputs = K.conv2d(\n",
        "            inputs,\n",
        "            binary_kernel,\n",
        "            strides=self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate)\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = {'H': self.H,\n",
        "                  'kernel_lr_multiplier': self.kernel_lr_multiplier,\n",
        "                  'bias_lr_multiplier': self.bias_lr_multiplier}\n",
        "        base_config = super(BinaryConv2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "# Aliases\n",
        "\n",
        "BinaryConvolution2D = BinaryConv2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIknyag6FvM0",
        "colab_type": "code",
        "outputId": "3bc4d872-ff6f-4944-e3f1-946ded29933b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3059
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "H = 1.\n",
        "kernel_lr_multiplier = 'Glorot'\n",
        "\n",
        "# nn\n",
        "batch_size = 50\n",
        "epochs = 50 \n",
        "channels = 3\n",
        "img_rows = 32 \n",
        "img_cols = 32 \n",
        "filters = 32 \n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2, 2)\n",
        "hidden_units = 128\n",
        "classes = 10\n",
        "use_bias = False\n",
        "\n",
        "# learning rate schedule\n",
        "lr_start = 1e-3\n",
        "lr_end = 1e-4\n",
        "lr_decay = (lr_end / lr_start)**(1. / epochs)\n",
        "\n",
        "# BN\n",
        "epsilon = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "# dropout\n",
        "p1 = 0.25\n",
        "p2 = 0.5\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape(50000, 3, 32, 32)\n",
        "X_test = X_test.reshape(10000, 3, 32, 32)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, classes) * 2 - 1 # -1 or 1 for hinge loss\n",
        "Y_test = np_utils.to_categorical(y_test, classes) * 2 - 1\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "# conv1\n",
        "model.add(BinaryConv2D(128, kernel_size=kernel_size, input_shape=(channels, img_rows, img_cols),\n",
        "                       data_format='channels_first',\n",
        "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier, \n",
        "                       padding='same', use_bias=use_bias, name='conv1'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn1'))\n",
        "model.add(Activation(binary_tanh, name='act1'))\n",
        "# conv2\n",
        "model.add(BinaryConv2D(128, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier, \n",
        "                       data_format='channels_first',\n",
        "                       padding='same', use_bias=use_bias, name='conv2'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, name='pool2', data_format='channels_first'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn2'))\n",
        "model.add(Activation(binary_tanh, name='act2'))\n",
        "# conv3\n",
        "model.add(BinaryConv2D(256, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
        "                       data_format='channels_first',\n",
        "                       padding='same', use_bias=use_bias, name='conv3'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn3'))\n",
        "model.add(Activation(binary_tanh, name='act3'))\n",
        "# conv4\n",
        "model.add(BinaryConv2D(256, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
        "                       data_format='channels_first',\n",
        "                       padding='same', use_bias=use_bias, name='conv4'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, name='pool4', data_format='channels_first'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn4'))\n",
        "model.add(Activation(binary_tanh, name='act4'))\n",
        "model.add(Flatten())\n",
        "# dense1\n",
        "model.add(BinaryDense(1024, H=H, kernel_lr_multiplier=kernel_lr_multiplier, use_bias=use_bias, name='dense5'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn5'))\n",
        "model.add(Activation(binary_tanh, name='act5'))\n",
        "# dense2\n",
        "model.add(BinaryDense(classes, H=H, kernel_lr_multiplier=kernel_lr_multiplier, use_bias=use_bias, name='dense6'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn6'))\n",
        "\n",
        "opt = Adam(lr=lr_start) \n",
        "model.compile(loss='squared_hinge', optimizer=opt, metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(X_test, Y_test),\n",
        "                    callbacks=[lr_scheduler])\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0620 08:53:32.802930 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0620 08:53:32.833362 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0620 08:53:32.840789 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0620 08:53:32.863382 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0620 08:53:32.864421 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0620 08:53:35.812807 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0620 08:53:35.915166 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0620 08:53:36.524353 139786215184256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0620 08:53:36.639060 139786215184256 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (BinaryConv2D)         (None, 128, 32, 32)       3456      \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 128, 32, 32)       128       \n",
            "_________________________________________________________________\n",
            "act1 (Activation)            (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2 (BinaryConv2D)         (None, 128, 32, 32)       147456    \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 128, 16, 16)       0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 128, 16, 16)       64        \n",
            "_________________________________________________________________\n",
            "act2 (Activation)            (None, 128, 16, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (BinaryConv2D)         (None, 256, 16, 16)       294912    \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 256, 16, 16)       64        \n",
            "_________________________________________________________________\n",
            "act3 (Activation)            (None, 256, 16, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv4 (BinaryConv2D)         (None, 256, 16, 16)       589824    \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 256, 8, 8)         0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 256, 8, 8)         32        \n",
            "_________________________________________________________________\n",
            "act4 (Activation)            (None, 256, 8, 8)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense5 (BinaryDense)         (None, 1024)              16777216  \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "act5 (Activation)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense6 (BinaryDense)         (None, 10)                10240     \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 10)                40        \n",
            "=================================================================\n",
            "Total params: 17,827,528\n",
            "Trainable params: 17,825,316\n",
            "Non-trainable params: 2,212\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.7711 - acc: 0.2796 - val_loss: 0.3608 - val_acc: 0.3331\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3251 - acc: 0.3528 - val_loss: 0.3150 - val_acc: 0.3647\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3081 - acc: 0.3826 - val_loss: 0.3047 - val_acc: 0.3922\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3007 - acc: 0.4061 - val_loss: 0.3064 - val_acc: 0.3947\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2939 - acc: 0.4275 - val_loss: 0.2923 - val_acc: 0.4169\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2888 - acc: 0.4403 - val_loss: 0.2886 - val_acc: 0.4364\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2844 - acc: 0.4518 - val_loss: 0.2843 - val_acc: 0.4439\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2799 - acc: 0.4654 - val_loss: 0.2788 - val_acc: 0.4646\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2760 - acc: 0.4752 - val_loss: 0.2857 - val_acc: 0.4464\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2732 - acc: 0.4822 - val_loss: 0.2816 - val_acc: 0.4519\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2702 - acc: 0.4911 - val_loss: 0.2733 - val_acc: 0.4718\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2677 - acc: 0.4949 - val_loss: 0.2713 - val_acc: 0.4856\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2649 - acc: 0.5049 - val_loss: 0.2716 - val_acc: 0.4834\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2620 - acc: 0.5104 - val_loss: 0.2721 - val_acc: 0.4831\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2600 - acc: 0.5167 - val_loss: 0.2749 - val_acc: 0.4733\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2582 - acc: 0.5209 - val_loss: 0.2674 - val_acc: 0.4895\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2559 - acc: 0.5247 - val_loss: 0.2654 - val_acc: 0.4970\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2546 - acc: 0.5304 - val_loss: 0.2651 - val_acc: 0.5025\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2532 - acc: 0.5338 - val_loss: 0.2629 - val_acc: 0.5043\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2512 - acc: 0.5388 - val_loss: 0.2638 - val_acc: 0.5077\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2500 - acc: 0.5406 - val_loss: 0.2609 - val_acc: 0.5097\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2486 - acc: 0.5431 - val_loss: 0.2593 - val_acc: 0.5129\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2468 - acc: 0.5484 - val_loss: 0.2646 - val_acc: 0.5033\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2457 - acc: 0.5492 - val_loss: 0.2573 - val_acc: 0.5191\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2447 - acc: 0.5538 - val_loss: 0.2625 - val_acc: 0.5121\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2432 - acc: 0.5561 - val_loss: 0.2623 - val_acc: 0.5183\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2428 - acc: 0.5589 - val_loss: 0.2559 - val_acc: 0.5159\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2409 - acc: 0.5631 - val_loss: 0.2559 - val_acc: 0.5213\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2402 - acc: 0.5651 - val_loss: 0.2556 - val_acc: 0.5222\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2384 - acc: 0.5672 - val_loss: 0.2625 - val_acc: 0.5111\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2372 - acc: 0.5714 - val_loss: 0.2616 - val_acc: 0.5129\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2369 - acc: 0.5738 - val_loss: 0.2527 - val_acc: 0.5324\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2354 - acc: 0.5760 - val_loss: 0.2545 - val_acc: 0.5254\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2350 - acc: 0.5762 - val_loss: 0.2584 - val_acc: 0.5155\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2342 - acc: 0.5810 - val_loss: 0.2588 - val_acc: 0.5198\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2341 - acc: 0.5787 - val_loss: 0.2559 - val_acc: 0.5343\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2315 - acc: 0.5854 - val_loss: 0.2518 - val_acc: 0.5359\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2313 - acc: 0.5840 - val_loss: 0.2520 - val_acc: 0.5399\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2314 - acc: 0.5848 - val_loss: 0.2555 - val_acc: 0.5240\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2304 - acc: 0.5877 - val_loss: 0.2531 - val_acc: 0.5295\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2296 - acc: 0.5915 - val_loss: 0.2524 - val_acc: 0.5314\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2295 - acc: 0.5924 - val_loss: 0.2528 - val_acc: 0.5350\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 0.2290 - acc: 0.5907 - val_loss: 0.2515 - val_acc: 0.5369\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2283 - acc: 0.5924 - val_loss: 0.2540 - val_acc: 0.5322\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2272 - acc: 0.5959 - val_loss: 0.2519 - val_acc: 0.5393\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2267 - acc: 0.5971 - val_loss: 0.2540 - val_acc: 0.5249\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2261 - acc: 0.5997 - val_loss: 0.2546 - val_acc: 0.5317\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 65s 1ms/step - loss: 0.2259 - acc: 0.6002 - val_loss: 0.2566 - val_acc: 0.5306\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 67s 1ms/step - loss: 0.2247 - acc: 0.6019 - val_loss: 0.2589 - val_acc: 0.5234\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2244 - acc: 0.6018 - val_loss: 0.2484 - val_acc: 0.5460\n",
            "Test score: 0.24836615543365478\n",
            "Test accuracy: 0.546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgmG7Eu6T1a_",
        "colab_type": "code",
        "outputId": "7ea38030-e0d6-4124-fb59-b0882ef9bf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "#accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqgwWkqQqg4UkqeoTGfgdsUCrRU0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsv8PR9Ts68XHD5gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}